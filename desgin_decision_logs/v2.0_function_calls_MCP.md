I am designing an MCP + RAG system. 

I already run and app that gatheres independent film listings and stores them in structued JSON.

Overall my tool will be used to take natural language queries about what listings are on and return actuall data search results. 

<summary><strong>Sample of my raw data for cinema listngs</strong></summary>
```json
{"barbican":{"Sentimental Value":{"description":"A marvellous and complex family drama from Joachim Trier, where a film-director reunites with his estranged daughter.","screen":"screen_1","screeningType":"standard","url":"https://www.barbican.org.uk/whats-on/2025/event/sentimental-value","when":[{"date":"2026-01-17","structured_date_strings":{"Weekday":"Saturday","Month":"January","day_str":"17th"},"month":1,"year":2026,"day":17,"showtimes":["18:00"]},{"date":"2026-01-18","structured_date_strings":{"Weekday":"Sunday","Month":"January","day_str":"18th"},"month":1,"year":2026,"day":18,"showtimes":["13:50"]}],"runtime":"2hr 13mins"},"Marty Supreme":{"description":"TimothÃ©e Chalamet serves rhythm and spin in Josh Safdie's new ping-pong comedy on big business, identity and feverish ambition.","screen":"screen_1","screeningType":"standard","url":"https://www.barbican.org.uk/whats-on/2025/event/marty-supreme","when":[{"date":"2026-01-17","structured_date_strings":{"Weekday":"Saturday","Month":"January","day_str":"17th"},"month":1,"year":2026,"day":17,"showtimes":["14:20","20:15"]},{"date":"2026-01-18","structured_date_strings":{"Weekday":"Sunday","Month":"January","day_str":"18th"},"month":1,"year":2026,"day":18,"showtimes":["19:10"]}],"runtime":"2hrs 29mins"}}}```

NOTE: baribcan is the cinema, next layer of keys (marty supreme and sentimental value) are the film titles) 

## 0) Current system I have built: app.py

**MVP DESIGN:**
I currently have a tool that does the following: 
1) takes a query str about film listings
2) uses a (versioned) llm parser to extract parameters from the suers queries as "intent", in the following format: 

```python
class Intent(TypedDict):
    cinemas: List[CinemaName]
    date_expression: str
    film_mention: str
```

3) then parses intent["date_expression"] into structured list of standard fromat date strings using (not yet versioned) "parse_dates()" parser

4) Uses RAG in a film resolver to map film_mention string to an film in my vector database (uses cosine simialirty match to match against all film names in my dataset)

5) Once cinema list, dates strigns and film ttiles have been extracted, the app.py returns a processed query of the following type: 

```python
class QueryDetails(TypedDict):
    raw_query: str #original user query
    cinemas: Optional[list[CinemaName]] #list of known cinema strings
    dates: Optional[list[str]] #list of yyyy-mm-dd strings
    matched_film_title: Optional[str] #film titles matched against films in my vectorDB
    raw_user_film_title: Optional[str] #film title extracted from raw_query - might not be in my DB
```


------------- NEXT PHASE: MCP FOR TOOL CALL [LEGACY] 
To start with  MCP does only two things:
1) Advertise available tools + their argument schemas
2) Let an LLM choose which tool to call and with what args

MCP therfore will: choose among capabilities, validate argument schemas, execute tools. 

------------- See the following Files for how MCP fits into my system: 

PIPLINE HANDLER:  kl_mcp_rag/pipeline_handler.py
- entry point to ML pipeline for user queries: 
- handler(query) -> pre_preocessor(query) -> params -> MCP 

QUERY-PRE-PROCESSOR (RAG): kl_mcp_rag/query_pre_processor.py (rename app.py)
- extracts film, dates, cinemas from user query (see above)

MCP SERVER: kl_mcp_rag/mcp_server/server.py: 
- MCP server to hold tools to be called, based on params extracted from user

MCP CLIENT: kl_mcp_rag/mcp_server/client.py: 
- Client for interface between processed queries and MCP server tools: 

```python
class MCPClient:
    def __init__(self):
        self.mcp_client_session: Optional[MCPClientSession] = None 
        self.exit_stack = AsyncExitStack() #manage async connections
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY")) #LLM client for tool calls etc. 

        # Load server path once during initialization
        self.server_script_path = self._get_server_script_path()

    async def close(self):
        "..."
        pass

    def _get_server_script_path(self) -> str:
        "..."
        pass

    async def connect_to_mcp_server(self):
        """client saved to class instace as async connection to MCPClientSession, 
        async connected via stdin + std out streams to  server process"""

        #  object for terminal command to start MCP server
        server_params = StdioServerParameters(
            command="python",
            args=[self.server_script_path],
        )

        #  Start MCP server w/ async stdio pipes 
        stdio, write = await self.exit_stack.enter_async_context(
            stdio_client(server_params)
        )

        # connect async to server stdin/out streams via client, stored in instance
        self.mcp_client_session = await self.exit_stack.enter_async_context(
            MCPClientSession(stdio, write)
        )

        # Initialize the MCP client session with mcp initilize() method:
        await self.mcp_client_session.initialize()

    async def list_tools(self):
        """List the MCP tools ..."""
        pass

    def build_tool_selection_prompt(
        self,
        preprocessed_query: Dict[str, Any],
        tools: list,
    ) -> str:
        """
        Build a prompt that asks the LLM to select the most appropriate MCP tool(s)
        and arguments based on the structured query intent...
        """
        pass

    async def select_tools_with_llm(self, prompt: str) -> str:
        """Tool-selection prompt -> LLM -> {JSON} describing which MCP tools to call."""
        pass
```
------------- ISSUE IDENTIFED: TOOL CALLS SHOULD BE DETERMINISTIC
